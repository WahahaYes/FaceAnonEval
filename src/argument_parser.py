import argparse
from typing import Iterator

from src.dataset.celeba_identity_lookup import CelebAIdentityLookup
from src.dataset.dataset_identity_lookup import DatasetIdentityLookup
from src.dataset.face_dataset import FaceDataset, dataset_iterator
from src.dataset.lfw_identity_lookup import LFWIdentityLookup
from src.privacy_mechanisms.gaussian_blur_mechanism import GaussianBlurMechanism
from src.privacy_mechanisms.privacy_mechanism import PrivacyMechanism
from src.privacy_mechanisms.test_mechanism import TestMechanism
from src.privacy_mechanisms.uniform_blur_mechanism import UniformBlurMechanism


# this class allows us to declare arguments all in one spot, with flags to specify
# whether certain args should appear for each user-facing script
class CustomArgumentParser:
    def __init__(self, mode: str = "process") -> None:
        self.mode = mode
        assert self.mode in ["process", "evaluate"], f"{self.mode} not valid!"

    def parse_args(self) -> argparse.Namespace:
        if self.mode == "process":
            parser = argparse.ArgumentParser(
                prog="Process Dataset",
                description="Processes an input dataset with a given anonymization method, "
                "producing an anonymized counterpart dataset used for later evaluation.",
            )
        elif self.mode == "evaluate":
            parser = argparse.ArgumentParser(
                prog="Evaluate Dataset.",
                description="Evaluates a benchmarking dataset (CelebA, lfw, etc.) against an "
                "anonymized counterpart using a selected evaluation methodology.",
            )
        # --------------------------------------------------------------------------
        # shared arguments
        parser.add_argument(
            "--dataset",
            choices=["CelebA", "lfw"],
            default="CelebA",
            type=str,
            help="The benchmark dataset to process, which should be placed into the 'Datasets' folder.",
        )
        parser.add_argument(
            "--celeba_test_set_only",
            default=True,
            type=bool,
            choices=[True, False],
            help="If using CelebA, whether to process only the test set or to process all 200k faces.",
        )
        parser.add_argument(
            "--privacy_mechanism",
            choices=["test", "gaussian_blur", "uniform_blur"],
            default="uniform_blur",
            type=str,
            help="The privacy operation to apply.",
        )
        parser.add_argument(
            "--batch_size",
            default=4,
            type=int,
            help="The batch size used by privacy mechanisms and facial recognition networks.",
        )
        # --------------------------------------------------------------------------
        # arguments applied to specific privacy mechanisms
        parser.add_argument(
            "--blur_kernel",
            default=5,
            type=int,
            help="For blurring operations, the size of the blur kernel.",
        )
        # --------------------------------------------------------------------------
        # arguments only relevant for processing script
        if self.mode == "process":
            parser.add_argument(
                "--output_path",
                default="Anonymized Datasets",
                type=str,
                help="Where to store the anonymized datasets (recommended to keep as default).",
            )

        # --------------------------------------------------------------------------
        # arguments only relevant for evaluation script
        if self.mode == "evaluate":
            parser.add_argument(
                "--anonymized_dataset",
                default=None,
                type=str,
                help="(Optional) The anonymized dataset to process, which should have been generated by "
                "'process_dataset.py' and located in the 'Anonymized Datasets' folder.  If this parameter is "
                "not explicitly passed, the dataset will be found based the 'privacy_operation' parameter.",
            )
            parser.add_argument(
                "--evaluation_method",
                choices=["rank_k", "lfw_validation"],
                default="rank_k",
                type=str,
                help="The evaluation methodology to use.  Some methods may rely on other arguments as hyperparameters.",
            )
            parser.add_argument(
                "--overwrite_embeddings",
                default=False,
                choices=[True, False],
                type=bool,
                help="Whether or not to overwrite any existing facial recognition embeddings that "
                "are cached for datasets that have previously been processed.",
            )
            # --------------------------------------------------------------------------
            # arguments applied to specific evaluation methods
            parser.add_argument(
                "--identity_matching_k",
                default=1,
                type=int,
                help="Choice of k in rank k identity matching.",
            )

        self.args = parser.parse_args()
        print(f"Arguments:\n{self.args}")
        return self.args

    def get_dataset_objects(
        self,
    ) -> (Iterator, FaceDataset, DatasetIdentityLookup):
        face_dataset: FaceDataset | None = None
        dataset_identity_lookup: DatasetIdentityLookup | None = None
        match self.args.dataset:
            case "CelebA":
                face_dataset = FaceDataset(
                    "Datasets//CelebA",
                    filetype=".jpg",
                    celeba_test_set_only=self.args.celeba_test_set_only,
                )
                dataset_identity_lookup = CelebAIdentityLookup(
                    identity_file_path="Datasets//CelebA//Anno//identity_CelebA.txt",
                    test_set_only=self.args.celeba_test_set_only,
                )
            case "lfw":
                face_dataset = FaceDataset("Datasets//lfw", filetype=".jpg")
                dataset_identity_lookup = LFWIdentityLookup()
            case _:
                raise Exception(f"Invalid Dataset argument ({self.args.dataset})")

        d_iter: Iterator = dataset_iterator(
            face_dataset, batch_size=self.args.batch_size
        )

        return d_iter, face_dataset, dataset_identity_lookup

    def get_privacy_mech_object(self) -> PrivacyMechanism:
        match self.args.privacy_mechanism:
            case "test":
                p_mech_object = TestMechanism()
            case "gaussian_blur":
                p_mech_object = GaussianBlurMechanism(kernel=self.args.blur_kernel)
            case "uniform_blur":
                p_mech_object = UniformBlurMechanism(kernel=self.args.blur_kernel)
            case _:
                raise Exception(
                    f"Invalid privacy operation argument ({self.args.privacy_mechanism})."
                )
        return p_mech_object
