{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import glob\n",
    "\n",
    "import cv2\n",
    "import insightface\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from torchvision import transforms\n",
    "\n",
    "from src.privacy_mechanisms.dtheta_privacy_mechanism import DThetaPrivacyMechanism\n",
    "from src.utils import (\n",
    "    img_tensor_to_cv2,\n",
    "    load_insightface_models,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.privacy_mechanisms.simswap.inference import embed_id\n",
    "\n",
    "# simswap_embeddings = []\n",
    "# for f_path in tqdm.tqdm(\n",
    "#     glob.glob(\n",
    "#         \"D:\\github\\FaceAnonEval\\Datasets\\CelebA_test\\Img\\img_align_celeba\\img_align_celeba\\*.jpg\"\n",
    "#     )\n",
    "# ):\n",
    "#     img = cv2.imread(f_path)\n",
    "#     embedding = embed_id(img)\n",
    "#     simswap_embeddings.append(embedding.cpu().detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simswap_embeddings = np.asarray(simswap_embeddings)\n",
    "# print(simswap_embeddings.shape)\n",
    "\n",
    "# import pickle\n",
    "\n",
    "# with open(\"simswap_embeddings.pickle\", \"wb\") as f:\n",
    "#     pickle.dump(simswap_embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading face detection model.\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CUDAExecutionProvider': {'cudnn_conv_algo_search': 'EXHAUSTIVE', 'device_id': '0', 'has_user_compute_stream': '0', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_external_alloc': '0', 'gpu_mem_limit': '18446744073709551615', 'enable_cuda_graph': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'prefer_nhwc': '0', 'use_ep_level_unified_stream': '0'}, 'CPUExecutionProvider': {}}\n",
      "Loading facial recognition model.\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CUDAExecutionProvider': {'cudnn_conv_algo_search': 'EXHAUSTIVE', 'device_id': '0', 'has_user_compute_stream': '0', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_external_alloc': '0', 'gpu_mem_limit': '18446744073709551615', 'enable_cuda_graph': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'prefer_nhwc': '0', 'use_ep_level_unified_stream': '0'}, 'CPUExecutionProvider': {}}\n"
     ]
    }
   ],
   "source": [
    "detect_model, recog_model = load_insightface_models()\n",
    "\n",
    "\n",
    "def load_image(img_path, size=256):\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    try:\n",
    "        bboxes, kpss = detect_model.detect(img)\n",
    "        img = insightface.utils.face_align.norm_crop(\n",
    "            img, landmark=kpss[0], image_size=size\n",
    "        )\n",
    "    except:\n",
    "        img = cv2.resize(img, (size, size))\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def generate_image(img, mechanism):\n",
    "    img = copy.copy(img)\n",
    "    img = transforms.ToTensor()(img)\n",
    "\n",
    "    result = mechanism.process(img[None, :])\n",
    "    gen_img = img_tensor_to_cv2(result[0, :])\n",
    "\n",
    "    return gen_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mechanism = DThetaPrivacyMechanism(theta=0, epsilon=0)\n",
    "mechanism.pad_ratio = 0\n",
    "\n",
    "img_tot = []\n",
    "\n",
    "for i in glob.glob(\"example_faces/*.png\"):\n",
    "    img = load_image(i, size=512)\n",
    "\n",
    "    img_row = []\n",
    "\n",
    "    for eps in [1, 10, 100, 1000]:\n",
    "        mechanism.epsilon = eps\n",
    "        priv_img = generate_image(img, mechanism)\n",
    "        img_row.append(priv_img)\n",
    "\n",
    "    img_row.append(img)\n",
    "\n",
    "    mechanism.epsilon = -1\n",
    "\n",
    "    for theta in [45, 90, 135, 180]:\n",
    "        mechanism.theta = theta\n",
    "        priv_img = generate_image(img, mechanism)\n",
    "        img_row.append(priv_img)\n",
    "\n",
    "    img_tot.append(np.concatenate(img_row, axis=1))\n",
    "\n",
    "\n",
    "cv2.imwrite(\"figures/dtheta_simswap.jpg\", np.concatenate(img_tot, axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "mechanism = DThetaPrivacyMechanism(theta=0, epsilon=0)\n",
    "mechanism.pad_ratio = 0\n",
    "\n",
    "os.makedirs(\"avatarldp_vis\", exist_ok=True)\n",
    "\n",
    "for i, fpath in enumerate(glob.glob(\"example_faces/*.png\")):\n",
    "    img = load_image(fpath, size=512)\n",
    "\n",
    "    cv2.imwrite(f\"avatarldp_vis/{i}.jpg\", img)\n",
    "\n",
    "    for eps in [5, 50, 500]:\n",
    "        img_col = []\n",
    "        for z in range(2):\n",
    "            img_row = []\n",
    "            for j in range(2):\n",
    "                mechanism.epsilon = eps\n",
    "                priv_img = generate_image(img, mechanism)\n",
    "                img_row.append(priv_img)\n",
    "            img_col.append(np.concatenate(img_row, axis=1))\n",
    "\n",
    "        img_tot = np.concatenate(img_col, axis=0)\n",
    "        cv2.imwrite(f\"avatarldp_vis/{i}_eps{eps}.jpg\", img_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DThetaPrivacyMechanism(theta=0, epsilon=-1)\n",
    "mechanism.pad_ratio = 0\n",
    "\n",
    "img_tot = []\n",
    "\n",
    "faces = glob.glob(\"example_faces/*.png\")\n",
    "\n",
    "for i in [0, 3, 2, 5]:\n",
    "    img = load_image(faces[i], size=512)\n",
    "\n",
    "    img_row = [img]\n",
    "\n",
    "    for theta in [30, 45, 60, 75, 90, 105, 120, 135]:\n",
    "        np.random.seed(1)\n",
    "\n",
    "        mechanism.theta = theta\n",
    "        priv_img = generate_image(img, mechanism)\n",
    "        img_row.append(priv_img)\n",
    "\n",
    "    img_tot.append(np.concatenate(img_row, axis=1))\n",
    "\n",
    "\n",
    "cv2.imwrite(\"figures/theta_slider.jpg\", np.concatenate(img_tot, axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.privacy_mechanisms.identity_dp_mechanism import IdentityDPMechanism\n",
    "from src.privacy_mechanisms.metric_privacy_mechanism import MetricPrivacyMechanism\n",
    "from src.privacy_mechanisms.pixel_dp_mechanism import PixelDPMechanism\n",
    "\n",
    "mechanisms = []\n",
    "# mechanisms.append(DThetaPrivacyMechanism(theta=90, epsilon=-1))\n",
    "# mechanisms[-1].pad_ratio = 0\n",
    "# mechanisms.append(DThetaPrivacyMechanism(theta=0, epsilon=1))\n",
    "# mechanisms[-1].pad_ratio = 0\n",
    "mechanisms.append(\"theta\")\n",
    "mechanisms.append(\"eps\")\n",
    "mechanisms.append(IdentityDPMechanism(epsilon=1))\n",
    "mechanisms[-1].pad_ratio = 0\n",
    "\n",
    "mechanisms.append(PixelDPMechanism(epsilon=5, b=4))\n",
    "mechanisms.append(MetricPrivacyMechanism(epsilon=5, k=8))\n",
    "\n",
    "img_labels = [\"00004\", \"00018\", \"00039\", \"00114\", \"00145\", \"00418\"]\n",
    "\n",
    "img_tot = []\n",
    "\n",
    "faces = glob.glob(\"example_faces/*.png\")\n",
    "\n",
    "for i in [1, 2, 4, 5]:\n",
    "    img = load_image(faces[i], size=512)\n",
    "\n",
    "    img_row = [img]\n",
    "\n",
    "    for mech in mechanisms:\n",
    "        if mech == \"eps\":\n",
    "            priv_img = cv2.imread(\n",
    "                f\"D://github/anonghost/results/{img_labels[i]}_eps1.0_theta0.0.jpg\"\n",
    "            )\n",
    "            priv_img = cv2.resize(priv_img, (512, 512))\n",
    "        elif mech == \"theta\":\n",
    "            priv_img = cv2.imread(\n",
    "                f\"D://github/anonghost/results/{img_labels[i]}_eps-1.0_theta60.0.jpg\"\n",
    "            )\n",
    "            priv_img = cv2.resize(priv_img, (512, 512))\n",
    "        else:\n",
    "            priv_img = generate_image(img, mech)\n",
    "        img_row.append(priv_img)\n",
    "\n",
    "    img_tot.append(np.concatenate(img_row, axis=0))\n",
    "\n",
    "\n",
    "cv2.imwrite(\"figures/baseline_comp.jpg\", np.concatenate(img_tot, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# anonghost figs\n",
    "faces = glob.glob(\"example_faces/*.png\")\n",
    "\n",
    "\n",
    "img_tot = []\n",
    "\n",
    "img_labels = [\"00004\", \"00018\", \"00039\", \"00114\", \"00145\", \"00418\"]\n",
    "\n",
    "\n",
    "for f in [1, 5, 0, 2, 3, 4]:\n",
    "    img = load_image(faces[f], size=512)\n",
    "\n",
    "    img_row = [img]\n",
    "\n",
    "    for theta in [30, 60, 90, 120, 150]:\n",
    "        priv_img = cv2.imread(\n",
    "            f\"D://github/anonghost/results/{img_labels[f]}_eps-1.0_theta{theta}.0.jpg\"\n",
    "        )\n",
    "        priv_img = cv2.resize(priv_img, (512, 512))\n",
    "        img_row.append(priv_img)\n",
    "\n",
    "    img_tot.append(np.concatenate(img_row, axis=1))\n",
    "\n",
    "\n",
    "cv2.imwrite(\"figures/anonghost_slider.jpg\", np.concatenate(img_tot, axis=0))\n",
    "\n",
    "img_tot = []\n",
    "\n",
    "for f in [0, 1, 2, 3, 4, 5]:\n",
    "    img = load_image(faces[f], size=512)\n",
    "\n",
    "    img_row = []\n",
    "\n",
    "    for eps in [1, 10, 100, 1000]:\n",
    "        priv_img = cv2.imread(\n",
    "            f\"D://github/anonghost/results/{img_labels[f]}_eps{eps}.0_theta0.0.jpg\"\n",
    "        )\n",
    "        priv_img = cv2.resize(priv_img, (512, 512))\n",
    "        img_row.append(priv_img)\n",
    "\n",
    "    img_row.append(img)\n",
    "\n",
    "    for theta in [45, 90, 135, 180]:\n",
    "        priv_img = cv2.imread(\n",
    "            f\"D://github/anonghost/results/{img_labels[f]}_eps-1.0_theta{theta}.0.jpg\"\n",
    "        )\n",
    "        priv_img = cv2.resize(priv_img, (512, 512))\n",
    "        img_row.append(priv_img)\n",
    "\n",
    "    img_tot.append(np.concatenate(img_row, axis=1))\n",
    "\n",
    "\n",
    "cv2.imwrite(\"figures/method_anonghost.jpg\", np.concatenate(img_tot, axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:00, 537.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"Results/Privacy/rank_k/CelebA_test_dtheta_privacy_theta0.0_eps0.0.csv\"\n",
    ")\n",
    "\n",
    "matches_df = df.loc[df[\"k\"] == 0]\n",
    "\n",
    "true_images, anon_images = [], []\n",
    "\n",
    "for i, row in tqdm.tqdm(matches_df.iterrows()):\n",
    "    if len(true_images) > 100:\n",
    "        break\n",
    "\n",
    "    query_key = row[\"query_key\"]\n",
    "    img_label = query_key.split(\"___\")[1]\n",
    "\n",
    "    anon_image = f\"Anonymized Datasets/CelebA_test_dtheta_privacy_theta0.0_eps0.0/Img/img_align_celeba/img_align_celeba/{img_label}.jpg\"\n",
    "    anon_image = cv2.imread(anon_image)\n",
    "    anon_images.append(anon_image)\n",
    "    true_image = (\n",
    "        f\"Datasets/CelebA_test/Img/img_align_celeba/img_align_celeba/{img_label}.jpg\"\n",
    "    )\n",
    "    true_image = cv2.imread(true_image)\n",
    "    true_images.append(true_image)\n",
    "\n",
    "\n",
    "true_images1 = np.concatenate(true_images[0:8], axis=1)\n",
    "anon_images1 = np.concatenate(anon_images[0:8], axis=1)\n",
    "true_images2 = np.concatenate(true_images[8:16], axis=1)\n",
    "anon_images2 = np.concatenate(anon_images[8:16], axis=1)\n",
    "true_images3 = np.concatenate(true_images[16:24], axis=1)\n",
    "anon_images3 = np.concatenate(anon_images[16:24], axis=1)\n",
    "\n",
    "cv2.imwrite(\n",
    "    \"figures/failure_cases_simswap.jpg\",\n",
    "    np.concatenate(\n",
    "        [\n",
    "            true_images1,\n",
    "            anon_images1,\n",
    "            true_images2,\n",
    "            anon_images2,\n",
    "            true_images3,\n",
    "            anon_images3,\n",
    "        ],\n",
    "        axis=0,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building an identity lookup table for CelebA.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 202599/202599 [00:00<00:00, 1595260.55it/s]\n",
      "2902it [00:04, 599.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.50206753962784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from src.dataset.celeba_identity_lookup import CelebAIdentityLookup\n",
    "\n",
    "idlookup = CelebAIdentityLookup(\n",
    "    identity_file_path=\"Datasets//CelebA//Anno//identity_CelebA.txt\"\n",
    ")\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"Results/Privacy/rank_k/CelebA_test_dtheta_privacy_theta0.0_eps0.0.csv\"\n",
    ")\n",
    "\n",
    "all_ids = []\n",
    "for i, row in df.iterrows():\n",
    "    all_ids.append(idlookup.lookup(row[\"query_key\"]))\n",
    "\n",
    "matches_df = df.loc[df[\"k\"] == 0]\n",
    "\n",
    "num_sames = []\n",
    "\n",
    "for i, row in tqdm.tqdm(matches_df.iterrows()):\n",
    "    query_key = row[\"query_key\"]\n",
    "    this_id = idlookup.lookup(query_key)\n",
    "\n",
    "    num_same = 0\n",
    "    for aid in all_ids:\n",
    "        if this_id == aid:\n",
    "            num_same += 1\n",
    "    num_sames.append(num_same)\n",
    "\n",
    "print(np.mean(num_sames))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FaceAnonEval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
